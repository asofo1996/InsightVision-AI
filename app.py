import streamlit as st
import os
import shutil
import glob
import cv2
import tempfile
import subprocess
import torch
import whisper
import yt_dlp
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# --- 1. ì‘ì—… í™˜ê²½ ì„¤ì • ë° í´ë” ìƒì„± (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„) ---
# ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ìœ„ì¹˜ì— 'uploaded' í´ë”ë¥¼ ìƒì„±í•˜ê³  ëª¨ë“  ì‘ì—…ì˜ ê¸°ì¤€ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
UPLOAD_DIR = os.path.join(os.getcwd(), "uploaded")

# ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ ì‘ì—… í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
try:
    if not os.path.exists(UPLOAD_DIR):
        st.info(f"ì‘ì—… í´ë”({UPLOAD_DIR})ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        os.makedirs(UPLOAD_DIR)
except Exception as e:
    st.error(f"ì‘ì—… í´ë” ìƒì„± ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.error("ìŠ¤í¬ë¦½íŠ¸ê°€ íŒŒì¼ì„ ì €ì¥í•  í´ë”ë¥¼ ìƒì„±í•  ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()


# --- 2. Streamlit UI ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="AI ì½˜í…ì¸  ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ¬ AI ì½˜í…ì¸  ë¶„ì„ ì‹œìŠ¤í…œ")
prompt_text = st.text_area("ë¶„ì„ í”„ë¡¬í”„íŠ¸", "Please analyze the content type, main audience, tone, and suggest 3 improvements.")


# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---

@st.cache_resource
def load_blip():
    """BLIP ì´ë¯¸ì§€ ìº¡ì…”ë‹ ëª¨ë¸ ë¡œë“œ"""
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return processor, model

def describe_image_with_blip(pil_image):
    """BLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±"""
    processor, model = load_blip()
    inputs = processor(pil_image, return_tensors="pt")
    out = model.generate(**inputs)
    return processor.decode(out[0], skip_special_tokens=True)

def get_latest_audio_file():
    """'uploaded' í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    supported_extensions = ["*.wav", "*.mp3", "*.m4a", "*.webm", "*.mp4", "*.ogg"]
    all_audio_files = []
    for ext in supported_extensions:
        all_audio_files.extend(glob.glob(os.path.join(UPLOAD_DIR, ext)))
    
    if not all_audio_files:
        return None
        
    latest_file = max(all_audio_files, key=os.path.getmtime)
    return latest_file

def safe_transcribe():
    """ê°€ì¥ ìµœì‹  ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì•„ Whisperë¡œ ìŒì„± ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    filepath = get_latest_audio_file()
    if not filepath:
        st.error(f"âŒ ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ì„ '{UPLOAD_DIR}' í´ë”ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.warning(f"í˜„ì¬ í´ë” ë‚´ìš©ë¬¼: {os.listdir(UPLOAD_DIR)}")
        raise FileNotFoundError("ë¶„ì„í•  ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.info(f"ğŸ§  ë¶„ì„ ëŒ€ìƒ ì˜¤ë””ì˜¤ íŒŒì¼: {filepath}")
    
    model = whisper.load_model("base")
    result = model.transcribe(filepath, fp16=torch.cuda.is_available(), language='ko')
    return result['text']

def extract_keyframes(video_path, fps=1):
    """ë¹„ë””ì˜¤ì—ì„œ í‚¤í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ 'uploaded' í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤."""
    cap = cv2.VideoCapture(video_path)
    # (ì´í•˜ í•¨ìˆ˜ ë‚´ìš©ì€ ì´ì „ê³¼ ë™ì¼)
    original_fps = cap.get(cv2.CAP_PROP_FPS)
    interval = int(original_fps / fps) if original_fps > 0 else 1
    frames = []
    count = 0
    frame_number = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        if count % interval == 0:
            path = os.path.join(UPLOAD_DIR, f"frame_{frame_number}.jpg")
            cv2.imwrite(path, frame)
            frames.append(path)
            frame_number += 1
        count += 1
    cap.release()
    return frames

def analyze_with_ollama(prompt_text):
    """Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰"""
    template = PromptTemplate.from_template("{prompt_text}")
    llm = Ollama(model="llama3")
    chain = LLMChain(prompt=template, llm=llm)
    return chain.run(prompt_text=prompt_text)

def summarize_all_inputs(frames_desc, transcript, title, prompt):
    """ëª¨ë“  ì…ë ¥ì„ í•˜ë‚˜ì˜ ìš”ì•½ í…ìŠ¤íŠ¸ë¡œ ê²°í•©"""
    summary = f"Title: {title}\n\n"
    summary += "Frame Descriptions:\n" + "\n".join([f"{i+1}. {desc}" for i, desc in enumerate(frames_desc)]) + "\n\n"
    summary += f"Transcript:\n{transcript}\n\n"
    summary += prompt.strip()
    return summary

def download_youtube_audio(url):
    """yt-dlpë¡œ ìœ íŠœë¸Œ ì˜¤ë””ì˜¤ë¥¼ ì›ë³¸ í˜•ì‹ ê·¸ëŒ€ë¡œ 'uploaded' í´ë”ì— ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    # ì¶œë ¥ ê²½ë¡œë¥¼ UPLOAD_DIRë¡œ ëª…í™•íˆ ì§€ì •
    output_template = os.path.join(UPLOAD_DIR, "youtube_audio.%(ext)s")
    
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': output_template,
        'noplaylist': True,
        # postprocessorsë¥¼ ì œê±°í•˜ì—¬ ì›ë³¸ í˜•ì‹(.m4a ë“±)ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
    }
    
    st.info(f"yt-dlpë¡œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì €ì¥ ê²½ë¡œ: {UPLOAD_DIR}")
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])
    st.success("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    st.info(f"í˜„ì¬ '{UPLOAD_DIR}' í´ë” ë‚´ìš©: {os.listdir(UPLOAD_DIR)}")


# --- 4. Streamlit UI ìƒì„¸ êµ¬ì„± ---
st.markdown("---")
st.subheader("íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ ë˜ëŠ” ìœ íŠœë¸Œ ë§í¬ë¡œ ë¶„ì„")

# íƒ­ UIë¡œ ë³€ê²½
tab1, tab2 = st.tabs(["íŒŒì¼ ì—…ë¡œë“œ", "ìœ íŠœë¸Œ ë§í¬ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ"])

with tab1:
    st.write("#### ì˜ìƒ, ì´ë¯¸ì§€, ìŒì„± íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
    uploaded_video = st.file_uploader("ì˜ìƒ ì—…ë¡œë“œ", type=["mp4", "mov", "mkv"])
    uploaded_image = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])
    uploaded_audio = st.file_uploader("ìŒì„± ì—…ë¡œë“œ", type=["wav", "mp3", "m4a"])

    if uploaded_image:
        image = Image.open(uploaded_image).convert("RGB")
        st.image(image, caption="ì—…ë¡œë“œ ì´ë¯¸ì§€")
        if st.button("ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘"):
            # (ì´í•˜ ë¶„ì„ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
            with st.spinner("ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                desc = describe_image_with_blip(image)
                final_prompt = f"Analyze the following image description:\n{desc}\n\nUser's Request:\n{prompt_text}"
                result = analyze_with_ollama(final_prompt)
                st.subheader("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼")
                st.write(result)
    
    # (ì˜ìƒ ë° ìŒì„± ì—…ë¡œë“œ ì²˜ë¦¬ ë¡œì§ì€ ìƒëµ. í•„ìš” ì‹œ ì´ì „ ì½”ë“œì—ì„œ ë³µì‚¬í•˜ì—¬ ì¶”ê°€ ê°€ëŠ¥)

with tab2:
    st.write("#### ìœ íŠœë¸Œ ë§í¬ ë˜ëŠ” ë¡œì»¬ ì»´í“¨í„°ì˜ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤.")
    mode = st.radio("ë°©ì‹ ì„ íƒ", ["ìœ íŠœë¸Œ ë§í¬", "ë¡œì»¬ íŒŒì¼ ê²½ë¡œ"], horizontal=True, key="tab2_mode")
    user_input = st.text_input("ë§í¬ ë˜ëŠ” ì „ì²´ íŒŒì¼ ê²½ë¡œ ì…ë ¥", key="tab2_input")

    if st.button("ì˜¤ë””ì˜¤ ìš”ì•½ ë¶„ì„ ì‹œì‘", key="tab2_button"):
        if not user_input:
            st.warning("ë§í¬ ë˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            try:
                with st.spinner("ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
                    if mode == "ìœ íŠœë¸Œ ë§í¬":
                        if not user_input.startswith("http"):
                            st.error("âŒ ìœ íš¨í•œ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        else:
                            download_youtube_audio(user_input)
                    else: # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ ëª¨ë“œ
                        if not os.path.exists(user_input):
                            raise FileNotFoundError(f"âŒ í•´ë‹¹ ê²½ë¡œì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {user_input}")
                        # íŒŒì¼ì„ UPLOAD_DIRë¡œ ë³µì‚¬
                        shutil.copy(user_input, UPLOAD_DIR)
                        st.info(f"ë¡œì»¬ íŒŒì¼ì„ '{UPLOAD_DIR}' í´ë”ë¡œ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.")

                    # ê³µí†µ ë¶„ì„ ë¡œì§
                    transcript = safe_transcribe()
                    final_prompt = f"Analyze the following transcript:\n{transcript}\n\nUser's Request:\n{prompt_text}"
                    
                    st.info("LLM ëª¨ë¸ë¡œ ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    result = analyze_with_ollama(final_prompt)
                    
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ")
                    st.subheader("ğŸ§ ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼")
                    st.code(transcript, language='text')
                    st.write(result)

            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)


st.markdown("---")
st.caption("Â© 2025 ì‹œì˜¨ë§ˆì¼€íŒ… | ê°œë°œì í™ì„í‘œ")
