# âœ… ìµœì¢… í†µí•© ë²„ì „: ì˜ìƒ/ìŒì„±/YouTube ë§í¬ ì—…ë¡œë“œ â†’ Whisper + BLIP + ìš”ì•½ ë¶„ì„ í¬í•¨

import streamlit as st
import os, tempfile, subprocess, torch
from PIL import Image
import whisper
import yt_dlp
import cv2
from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

st.set_page_config(page_title="AI ì½˜í…ì¸  ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")
st.title("AI ë¶„ì„ ì‹œìŠ¤í…œ")

# Whisper ë° ìš”ì•½ê¸° ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

@st.cache_resource
def load_blip():
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return processor, model

# YouTube ë‹¤ìš´ë¡œë“œ
def download_youtube_audio(url):
    temp_dir = tempfile.mkdtemp()
    mp3_path = os.path.join(temp_dir, "youtube_audio.mp3")
    wav_path = os.path.join(temp_dir, "youtube_audio.wav")
    for path in [mp3_path, wav_path]:
        if os.path.exists(path): os.remove(path)
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': mp3_path,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3'
        }]
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])
    subprocess.run(["ffmpeg", "-y", "-i", mp3_path, "-ac", "1", "-ar", "16000", wav_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return wav_path

# ì˜ìƒ í”„ë ˆì„ ì¶”ì¶œ
def extract_frames(video_path, fps=1):
    cap = cv2.VideoCapture(video_path)
    original_fps = cap.get(cv2.CAP_PROP_FPS)
    interval = int(original_fps * fps)
    frames = []
    count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % interval == 0:
            temp_file = os.path.join(tempfile.gettempdir(), f"frame_{count}.jpg")
            cv2.imwrite(temp_file, frame)
            frames.append(temp_file)
        count += 1
    cap.release()
    return frames

# ì´ë¯¸ì§€ ì„¤ëª…
def describe_image(pil_image):
    processor, model = load_blip()
    inputs = processor(pil_image, return_tensors="pt")
    output = model.generate(**inputs)
    return processor.decode(output[0], skip_special_tokens=True)

# Whisperë¡œ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜
def transcribe_audio(path):
    model = load_whisper_model()
    result = model.transcribe(path)
    return result['text']

# ìš”ì•½ ìƒì„±
def summarize_text(text):
    summarizer = load_summarizer()
    chunks = [text[i:i+1000] for i in range(0, len(text), 1000)]
    summaries = [summarizer(chunk)[0]['summary_text'] for chunk in chunks]
    return " ".join(summaries)

# Ollama ë¶„ì„ (ì˜µì…˜)
def analyze_with_ollama(prompt_text):
    template = PromptTemplate.from_template("""{prompt_text}""")
    llm = Ollama(model="llama3")
    chain = LLMChain(prompt=template, llm=llm)
    return chain.run(prompt_text=prompt_text)

# ë¶„ì„ ì§€ì‹œë¬¸
prompt_text = st.text_area("ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ì„ íƒ)", "Please analyze the content type, main audience, tone, and suggest 3 improvements.")

# ì…ë ¥ ë°©ì‹ ì„ íƒ
st.subheader("ğŸ¬ ì˜ìƒ / ìŒì„± / YouTube ë¶„ì„")
mode = st.radio("ì…ë ¥ ë°©ì‹", ["ìœ íŠœë¸Œ ë§í¬", "ë¡œì»¬ ìŒì„± íŒŒì¼", "ë¡œì»¬ ì˜ìƒ íŒŒì¼"])

if mode == "ìœ íŠœë¸Œ ë§í¬":
    url = st.text_input("ìœ íŠœë¸Œ ë§í¬")
    if st.button("YouTube ë¶„ì„ ì‹œì‘") and url:
        with st.spinner("YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ ì¤‘..."):
            try:
                audio_path = download_youtube_audio(url)
                transcript = transcribe_audio(audio_path)
                summary = summarize_text(transcript)
                st.success("âœ… ë¶„ì„ ì™„ë£Œ")
                st.text_area("ì „ì²´ í…ìŠ¤íŠ¸", transcript, height=250)
                st.subheader("ìš”ì•½ ê²°ê³¼")
                st.info(summary)
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif mode == "ë¡œì»¬ ìŒì„± íŒŒì¼":
    audio_file = st.file_uploader("ìŒì„±(mp3/wav) ì—…ë¡œë“œ", type=["mp3", "wav"])
    if st.button("ìŒì„± ë¶„ì„ ì‹œì‘") and audio_file:
        with st.spinner("ìŒì„± íŒŒì¼ ë¶„ì„ ì¤‘..."):
            try:
                temp_audio = os.path.join(tempfile.gettempdir(), audio_file.name)
                with open(temp_audio, "wb") as f:
                    f.write(audio_file.read())
                transcript = transcribe_audio(temp_audio)
                summary = summarize_text(transcript)
                st.success("âœ… ë¶„ì„ ì™„ë£Œ")
                st.text_area("ì „ì²´ í…ìŠ¤íŠ¸", transcript, height=250)
                st.subheader("ìš”ì•½ ê²°ê³¼")
                st.info(summary)
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif mode == "ë¡œì»¬ ì˜ìƒ íŒŒì¼":
    video_file = st.file_uploader("ì˜ìƒ(mp4) ì—…ë¡œë“œ", type=["mp4"])
    if st.button("ì˜ìƒ ë¶„ì„ ì‹œì‘") and video_file:
        with st.spinner("ì˜ìƒ ë¶„ì„ ì¤‘ (í”„ë ˆì„ + ìŒì„±)..."):
            try:
                temp_video = os.path.join(tempfile.gettempdir(), video_file.name)
                with open(temp_video, "wb") as f:
                    f.write(video_file.read())

                # í”„ë ˆì„ ë¶„ì„
                frames = extract_frames(temp_video)
                descs = [describe_image(Image.open(p)) for p in frames[:5]]
                st.subheader("ì˜ìƒ í”„ë ˆì„ ì„¤ëª… ìš”ì•½")
                st.markdown("\n".join([f"- {d}" for d in descs]))

                # ìŒì„± ì¶”ì¶œ
                audio_path = os.path.join(tempfile.gettempdir(), "video_audio.wav")
                subprocess.run(["ffmpeg", "-y", "-i", temp_video, "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", audio_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                transcript = transcribe_audio(audio_path)
                summary = summarize_text(transcript)
                st.subheader("ìŒì„± í…ìŠ¤íŠ¸")
                st.text_area("ì „ì²´ í…ìŠ¤íŠ¸", transcript, height=250)
                st.subheader("ìš”ì•½ ê²°ê³¼")
                st.info(summary)
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.caption("Â© 2025 ì‹œì˜¨ë§ˆì¼€íŒ… | ê°œë°œì í™ì„í‘œ")
