import streamlit as st
import os
import tempfile
import subprocess
from pathlib import Path
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import whisper
import yt_dlp

# Streamlit ì„¤ì •
st.set_page_config(page_title="AI ì½˜í…ì¸  ë¶„ì„ ì‹œìŠ¤í…œ", layout="wide")
st.title("AI ë¶„ì„ ì‹œìŠ¤í…œ")

# ì…ë ¥ í”„ë¡¬í”„íŠ¸
prompt_text = st.text_area("ë¶„ì„ í”„ë¡¬í”„íŠ¸", "Please analyze the content type, main audience, tone, and suggest 3 improvements.")

# ëª¨ë¸ ìºì‹±
@st.cache_resource
def load_blip():
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return processor, model

def describe_image_with_blip(pil_image):
    processor, model = load_blip()
    inputs = processor(pil_image, return_tensors="pt")
    out = model.generate(**inputs)
    return processor.decode(out[0], skip_special_tokens=True)

def analyze_with_ollama(prompt_text):
    template = PromptTemplate.from_template("{prompt_text}")
    llm = Ollama(model="llama3")
    chain = LLMChain(prompt=template, llm=llm)
    return chain.run(prompt_text=prompt_text)

def convert_to_wav(input_path, output_path):
    command = ["ffmpeg", "-y", "-i", input_path, "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1", output_path]
    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def transcribe_audio(audio_path):
    model = whisper.load_model("base")
    result = model.transcribe(audio_path, fp16=False)
    return result["text"]

def download_youtube_audio(url, output_path):
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": str(output_path),
        "quiet": True,
        "postprocessors": [
            {"key": "FFmpegExtractAudio", "preferredcodec": "mp3", "preferredquality": "192"}
        ],
    }
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([url])

def process_audio_source(uploaded_file=None, youtube_link=None):
    temp_dir = tempfile.gettempdir()
    input_path = Path(temp_dir) / "youtube_audio.mp3"
    wav_path = Path(temp_dir) / "converted_audio.wav"

    # íŒŒì¼ ì €ì¥ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ
    if youtube_link:
        download_youtube_audio(youtube_link, input_path)
    elif uploaded_file:
        input_path.write_bytes(uploaded_file.read())
    else:
        raise ValueError("No valid audio source")

    convert_to_wav(input_path, wav_path)
    transcript = transcribe_audio(str(wav_path))
    summary = analyze_with_ollama(f"Transcript:\n{transcript}\n\n{prompt_text}")
    return transcript, summary

# ì„ íƒ íƒ­
mode = st.radio("ë¶„ì„ ë°©ì‹ ì„ íƒ", ["ìœ íŠœë¸Œ ë§í¬", "ì˜ìƒ/ìŒì„± ì—…ë¡œë“œ", "ì´ë¯¸ì§€ ì—…ë¡œë“œ"])

if mode == "ìœ íŠœë¸Œ ë§í¬":
    yt_url = st.text_input("ìœ íŠœë¸Œ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if st.button("ì˜¤ë””ì˜¤ ìš”ì•½ ë¶„ì„ ì‹œì‘"):
        try:
            with st.spinner("ìœ íŠœë¸Œ ìŒì„± ë¶„ì„ ì¤‘..."):
                transcript, summary = process_audio_source(youtube_link=yt_url)
            st.success("âœ… ë¶„ì„ ì™„ë£Œ")
            st.subheader("ğŸ§ ì „ì²´ í…ìŠ¤íŠ¸")
            st.write(transcript)
            st.subheader("ğŸ§  ìš”ì•½ ê²°ê³¼")
            st.write(summary)
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif mode == "ì˜ìƒ/ìŒì„± ì—…ë¡œë“œ":
    uploaded_audio = st.file_uploader("ğŸ§ ì˜ìƒ ë˜ëŠ” ìŒì„± íŒŒì¼ ì—…ë¡œë“œ", type=["mp3", "wav", "mp4"])
    if uploaded_audio and st.button("ì—…ë¡œë“œ ë¶„ì„ ì‹œì‘"):
        try:
            with st.spinner("ì—…ë¡œë“œí•œ íŒŒì¼ ë¶„ì„ ì¤‘..."):
                transcript, summary = process_audio_source(uploaded_file=uploaded_audio)
            st.success("âœ… ë¶„ì„ ì™„ë£Œ")
            st.subheader("ğŸ§ ì „ì²´ í…ìŠ¤íŠ¸")
            st.write(transcript)
            st.subheader("ğŸ§  ìš”ì•½ ê²°ê³¼")
            st.write(summary)
        except Exception as e:
            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif mode == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
    uploaded_image = st.file_uploader("ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])
    if uploaded_image and st.button("ì´ë¯¸ì§€ ì„¤ëª… ë° ë¶„ì„ ì‹œì‘"):
        with st.spinner("ì´ë¯¸ì§€ ì„¤ëª… ì¤‘..."):
            pil = Image.open(uploaded_image).convert("RGB")
            description = describe_image_with_blip(pil)
        with st.spinner("ì„¤ëª… ê¸°ë°˜ ë¶„ì„ ì¤‘..."):
            result = analyze_with_ollama(f"Image Description:\n{description}\n\n{prompt_text}")
        st.success("âœ… ë¶„ì„ ì™„ë£Œ")
        st.subheader("ğŸ“„ ë¶„ì„ ê²°ê³¼")
        st.write(result)

# í•˜ë‹¨
st.caption("Â© 2025 ì‹œì˜¨ë§ˆì¼€íŒ… | ê°œë°œì í™ì„í‘œ")
